{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb0077a",
   "metadata": {},
   "source": [
    "# BIG DATA ANALYTICS AND RNN IN BANANA PRICE FORECASTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d67de0",
   "metadata": {},
   "source": [
    "## STOP ANY ACTIVE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Stop all active Spark sessions\n",
    "SparkSession.builder.getOrCreate().stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd223e",
   "metadata": {},
   "source": [
    "## Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc589e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyspark.ml import Pipeline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec5b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the contents of the root directory in HDFS\n",
    "!hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6b73b",
   "metadata": {},
   "source": [
    "## Preprocessing Data using Spark\n",
    "This process involves a series of steps. They include:-\n",
    "1. Loading 2 CSV files on national average prices of food data stored in hadoop.\n",
    "\n",
    "2. Data Exploration: Perform exploratory data analysis (EDA) \n",
    "\n",
    "3. Data integration, merging the two csv datasets\n",
    "\n",
    "4. Data Export: Export the preprocessed data to hadoop for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625a7ad",
   "metadata": {},
   "source": [
    "## Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b4dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hadoop to python\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8947e",
   "metadata": {},
   "source": [
    "## Step one: Load the data from hadoop using spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d106832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The two datasets hadoop path\n",
    "dataset_one = \"hdfs://localhost:9000/CPM04.20240327101259.csv\"\n",
    "dataset_two = \"hdfs://localhost:9000/CPM12.20240327101308.csv\"\n",
    "\n",
    "#Create spark DataFrames for the two datasets\n",
    "df_one = spark.read.csv(dataset_one, header=True, inferSchema=True)\n",
    "df_two = spark.read.csv(dataset_two, header=True, inferSchema=True)\n",
    "\n",
    "#View the two DataFRames\n",
    "df_one, df_two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556ab72",
   "metadata": {},
   "source": [
    "## Step Two: Performing Explorartory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first two observations of dataset one\n",
    "df_one.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first two observations fo dataset two \n",
    "df_two.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a2b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Schema for dataset one\n",
    "df_one.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62176ee5",
   "metadata": {},
   "source": [
    "## Findings\n",
    "Shows there is missing data in all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Schema for dataset two\n",
    "df_two.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37493e8d",
   "metadata": {},
   "source": [
    "## Findings\n",
    "SHows there is missing data in all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the cahracteristics of the datasets\n",
    "df_one.describe(), df_two.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508216ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of observations\n",
    "dataone_count = df_one.count()\n",
    "\n",
    "print(\"Number of observations:\", dataone_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead06fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of observations\n",
    "datatwo_count = df_two.count()\n",
    "\n",
    "print(\"Number of observations:\", datatwo_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aeb907",
   "metadata": {},
   "source": [
    "# Delete variables that will be unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71803ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all columns except month, consumer item and VALUE)\n",
    "df_one = df_one.drop(\"STATISTIC\",\"STATISTIC Label\",\"TLIST(M1)\",\"UNIT\",\"C02363V02844\")\n",
    "df_one.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05165bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all columns except month, consumer item and VALUE)\n",
    "df_two = df_two.drop(\"STATISTIC\",\"STATISTIC Label\",\"TLIST(M1)\",\"UNIT\",\"C02363V03422\")\n",
    "df_two.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631a0d8",
   "metadata": {},
   "source": [
    "## Drop from consumer Item, everything except bananas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f33817",
   "metadata": {},
   "outputs": [],
   "source": [
    "bananaprice_one = df_one.filter(df_one[\"Consumer Item\"] == \"Bananas per kg.\")\n",
    "bananaprice_two = df_two.filter(df_two[\"Consumer Item\"] == \"Bananas per kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "bananaprice_one.show(), bananaprice_two.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc81ee",
   "metadata": {},
   "source": [
    "## Step Three: Data Integration. Merging the two datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baeb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in df1 to match columns in df2\n",
    "rename_mapping = {\n",
    "    \"VALUE\": \"National Average Price(Euros)\"\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "for old_col, new_col in rename_mapping.items():\n",
    "    bananaprice_one = bananaprice_one.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43090fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in df1 to match columns in df2\n",
    "rename_mapping = {\n",
    "    \"VALUE\":\"National Average Price(Euros)\"\n",
    "}\n",
    "for old_col, new_col in rename_mapping.items():\n",
    "    bananaprice_two = bananaprice_two.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6395f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bananaprice_one.show(), bananaprice_two.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns in the same order\n",
    "bananaprice_one = bananaprice_one.select(\"Consumer Item\", \"Month\", \"National Average Price(Euros)\")\n",
    "bananaprice_two = bananaprice_two.select(\"Consumer Item\", \"Month\", \"National Average Price(Euros)\")\n",
    "\n",
    "# Performing the union operation\n",
    "merged_df = bananaprice_one.union(bananaprice_two)\n",
    "\n",
    "# Displaying the results\n",
    "merged_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.show(n=merged_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6616bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of observations\n",
    "mergeddata_count = merged_df.count()\n",
    "\n",
    "print(\"Number of observations:\", mergeddata_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc8c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4445adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Missing data\n",
    "# Remove rows with missing values\n",
    "cleaned_df = merged_df.na.drop()\n",
    "\n",
    "# Show the cleaned DataFrame\n",
    "cleaned_df.show(n=cleaned_df.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on the date column\n",
    "duplicated_df = cleaned_df.dropDuplicates(['Month'])\n",
    "\n",
    "# Count the number of duplicates\n",
    "num_duplicates = cleaned_df.count() - duplicated_df.count()\n",
    "\n",
    "# Show the number of duplicates\n",
    "print(\"Number of duplicates based on date:\", num_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd54f9",
   "metadata": {},
   "source": [
    "## EXPORT THE PREPROCESSED DATA TO HADOOP FOR STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export preprocessed data\n",
    "preprocessed_data_path = \"hdfs://localhost:9000/preprocessed_data.csv\"\n",
    "cleaned_df.write.csv(preprocessed_data_path, mode=\"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340725ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99983a",
   "metadata": {},
   "source": [
    "# Convert the data to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2973a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "banana_price = cleaned_df.toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
